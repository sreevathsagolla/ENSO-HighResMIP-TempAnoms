{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2eaaf5-3016-46b0-af35-3933da4df2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Code for preparing data for CMIP6 HighResMIP, NPD_eORCA025 and Obs.-based Products\n",
    "\n",
    "Processing in this notebook includes:\n",
    "-------------------------------------\n",
    "1. Computing con. temperature data and interpolating/remapping to a regular lat-lon grid \n",
    "over the Pacific (30˚S-30˚N; 120˚E-290˚E), using bilinear interpolation. The grid description\n",
    "for which was manually configured to be a 0.25˚ regular grid and saved as ./data/griddes_025.grd\n",
    "2. Calculating anomalies using centred moving 30yr baselines, for which the bounds were\n",
    "manually configured and saved as a .csv files in ./data/ (with prefix as Centred_BS_bounds),\n",
    "separetely for CMIP6 HighResMIP total period (1950-2050) and Observational datasets and NPD_eOR025 \n",
    "runs (1976-2023).\n",
    "3. Calculate depth of 20˚ isotherm from computed con. temp data, and saving the file.\n",
    "4. Compute zonal wind anomalies at 850hPa for CMIP6 HighResMIP and ERA5 Reanalysis.\n",
    "-------------------------------------------------------------------------------------------\n",
    "Author: Sreevathsa G. (sg13n23@soton.ac.uk; ORCID ID: 0000-0003-4084-9677)\n",
    "Last updated: 11 December 2025\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449a43d3-419a-41ee-8c2c-2a0d88f7b38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dssgfs01/working/sg13n23/miniconda3/lib/python3.12/site-packages/pyproj/__init__.py:89: UserWarning: pyproj unable to set database path.\n",
      "  _pyproj_global_context_initialize()\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import sys\n",
    "import gsw\n",
    "import glob\n",
    "import xarray as xr\n",
    "import os\n",
    "from itertools import product\n",
    "from utils import *\n",
    "from cdo import *\n",
    "cdo = Cdo()\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "# Dask cluster\n",
    "import dask\n",
    "from dask.distributed import Client, LocalCluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fded09b5-b97c-4924-ba47-7523404b2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DASK CLUSTER SETUP (ON ANEMONE HPC @ NOCS, UK)\n",
    "# =============================================================================\n",
    "def setup_dask_cluster(n_workers=6, threads_per_worker=3, memory_limit=\"48GB\"):\n",
    "    \"\"\"Initialize and return a Dask cluster and client.\"\"\"\n",
    "    dask.config.set({\n",
    "        \"temporary_directory\": \"/dssgfs01/scratch/sg13n23/temp/\",\n",
    "        \"local_directory\": \"/dssgfs01/scratch/sg13n23/temp/\"\n",
    "    })\n",
    "    cluster = LocalCluster(\n",
    "        n_workers=n_workers,\n",
    "        threads_per_worker=threads_per_worker,\n",
    "        memory_limit=memory_limit\n",
    "    )\n",
    "    client = Client(cluster)\n",
    "    return cluster, client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26995df5-65ce-4e89-a1ca-cf0eac4613a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset name lists\n",
    "PARENT_DIR = '/badc/cmip6/data/CMIP6/HighResMIP/'\n",
    "HIGHRESMIP_MODEL_PATH_SUFFIX = ['MPI-ESM1-2-HR']#, 'MPI-ESM1-2-XR', 'HadGEM3-GC31-HH', \n",
    "                                #'EC-Earth3P-HR', 'CMCC-CM2-VHR4', 'CNRM-CM6-1-HR']\n",
    "EXP_TYPES = {'CTRL' : ['control-1950'], \n",
    "             'HIST-FUT' : ['hist-1950', 'highres-future']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505836a-9159-4ad9-a004-7f346548f3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the Dask client for this notebook.\n",
    "cluster, client = setup_dask_cluster()\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1de01c6-c8b4-4ac9-9230-3a2f2b79a4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def cdo_remapbil(filename_list, var_name):\n",
    "    ds = []\n",
    "    for f in filename_list:\n",
    "        ds += [renamer(cdo.remapbil('./data/griddes_025.grd', input=f'-selvar,{var_name} '+f, returnXDataset = True))]\n",
    "    ds = xr.concat(ds, dim = 'time')\n",
    "    return ds\n",
    "\n",
    "# Calculate Z20\n",
    "def z20_calculator(ds):\n",
    "    abs_diff = abs(ds['thetao_con'] - 20)\n",
    "    valid_mask = abs_diff.notnull().any(dim='depth')\n",
    "    abs_diff = abs_diff.where(valid_mask)\n",
    "    min_index = abs_diff.fillna(np.inf).argmin(dim='depth')\n",
    "    z20 = ds['depth'].isel(depth=min_index).where(valid_mask).rename('z20')\n",
    "    return z20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b587b39b-b6d3-4c9d-b847-2f7871e6d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATING CON. TEMPERATURE DATA OVER A PACIFIC SUBSET USING A GSW FUNCTION\n",
    "# =============================================================================\n",
    "\n",
    "# CMIP6 HighResMIP\n",
    "for model, exp_type in tqdm(list(product(HIGHRESMIP_MODEL_PATH_SUFFIX, EXP_TYPES))):\n",
    "    # Creating a {model}_{exp_type} directory if it doesn't exist\n",
    "    if os.path.exists(f'./data/thetao_con/{model}_{exp_type}/') == False:\n",
    "        os.mkdir(f'./data/thetao_con/{model}_{exp_type}/')\n",
    "    for year in tqdm(np.arange(1950, 2050+1), leave = False):\n",
    "        # Filenames corresponding to each year's data: pt = potential temperature (var_name : thetao, in degC) and so = absolute salinity (var_name : so, in g/kg)\n",
    "        fnames_pt = flatten([sorted(glob.glob(PARENT_DIR + f'*/{model}/{exp_id}/r1*/Omon/thetao/*/latest/*{year}??.nc')) for exp_id in EXP_TYPES[exp_type]])\n",
    "        fnames_so = flatten([sorted(glob.glob(PARENT_DIR + f'*/{model}/{exp_id}/r1*/Omon/so/*/latest/*{year}??.nc')) for exp_id in EXP_TYPES[exp_type]])\n",
    "        # Ensuring the lists are not empty i.e., files for the iterated year exists\n",
    "        if (fnames_pt != []) & (fnames_so != []):\n",
    "            # Reading and bilinearly interpolating the data into a 0.25deg regular lat-lon grid\n",
    "            ds_thetao = cdo_remapbil(filename_list = fnames_pt, var_name = 'thetao')\n",
    "            ds_so = cdo_remapbil(filename_list = fnames_so, var_name = 'so')\n",
    "            # Computing conservative temperature from potential temperature and salinity using gsw.conversions.CT_from_pt function\n",
    "            ds = gsw.conversions.CT_from_pt(SA = ds_so['so'], pt = ds_thetao['thetao']).rename('thetao_con').to_dataset()\n",
    "            # Saving the file as a single-year file\n",
    "            ds.to_netcdf(f'./data/thetao_con/{model}_{exp_type}/BILINTERP_PAC_THETAO_CON_CMIP6_HIGHRESMIP_{model}_{exp_type}_{year}.nc')\n",
    "    # Cleaning-up\n",
    "    cdo.cleanTempDir()\n",
    "    \n",
    "# Observations-based Products (OBS)\n",
    "for obs_dataset in ['ORAS5', 'EN4']:\n",
    "    for ts in tqdm(pd.date_range(start = '1976-01-01', end = '2023-12-31', freq = '1MS')):\n",
    "        if os.path.exists(f'./data/thetao_con/{obs_dataset}/') == False:\n",
    "            os.mkdir(f'./data/thetao_con/{obs_dataset}/')\n",
    "\n",
    "        if obs_dataset == 'ORAS5':\n",
    "            f_so = glob.glob(f'/gws/nopw/j04/nemo_vol1/golla/OBS_DATA/ORAS5/orig_data/vosaline*{ts.year}{ts.month:02d}*')[0]\n",
    "            f_pt = glob.glob(f'/gws/nopw/j04/nemo_vol1/golla/OBS_DATA/ORAS5/orig_data/votemper*{ts.year}{ts.month:02d}*')[0]\n",
    "            varname_pt = 'votemper'\n",
    "            varname_so = 'vosaline'\n",
    "        elif obs_dataset == 'EN4':\n",
    "            f_so = f_pt = f'/gws/nopw/j04/nemo_vol1/golla/OBS_DATA/EN4/orig_data/EN.4.2.2.f.analysis.g10.{ts.year}{ts.month:02d}.nc'\n",
    "            varname_pt = 'temperature'\n",
    "            varname_so = 'salinity'\n",
    "            \n",
    "        # Reading and bilinearly interpolating the data into a 0.25deg regular lat-lon grid\n",
    "        ds_thetao = cdo_remapbil(filename_list = [f_pt], var_name = varname_pt)\n",
    "        ds_so = cdo_remapbil(filename_list = [f_so], var_name = varname_so)\n",
    "        # Computing conservative temperature from potential temperature and salinity using gsw.conversions.CT_from_pt function\n",
    "        ds = gsw.conversions.CT_from_pt(SA = ds_so[varname_so], pt = ds_thetao[varname_pt]).rename('thetao_con').to_dataset()\n",
    "        # Setting time axis appropriately\n",
    "        ds['time'] = pd.to_datetime([str(_)[0:8]+'01' for _ in ds['time'].values])\n",
    "        # Saving the file as a single-year file\n",
    "        ds.to_netcdf(f'./data/thetao_con/{obs_dataset}/BILINTERP_PAC_THETAO_CON_{obs_dataset}_{ts.year}{ts.month:02d}.nc')\n",
    "        # Cleaning-up\n",
    "        cdo.cleanTempDir()  \n",
    "\n",
    "# NPD_eORCA025 exps. (NOTE: thetao_con is pre-calculated online when the model is run, so just bilinearly interpolating and saving data here).\n",
    "for npd_exp in ['NPD_eORCA025_ERA5', 'NPD_eORCA025_JRA55']:\n",
    "    for ts in tqdm(pd.date_range(start = '1976-01-01', end = '2023-12-31', freq = '1MS')):\n",
    "        fname = f'/dssgfs01/scratch/npd/simulations/{npd_exp[4:]}/{ts.year}/eORCA025_1m_grid_T_{ts.year}{ts.month:02d}-{ts.year}{ts.month:02d}.nc'\n",
    "        ds = cdo_remapbil(filename_list = [fname], var_name = 'thetao_con')['thetao_con'].to_dataset()\n",
    "        # Setting time axis appropriately\n",
    "        ds['time'] = pd.to_datetime([str(_)[0:8]+'01' for _ in ds['time'].values])\n",
    "        # Saving the file as a single-year file\n",
    "        ds.to_netcdf(f'./data/thetao_con/{npd_exp}/BILINTERP_PAC_THETAO_CON_{npd_exp}_{ts.year}{ts.month:02d}.nc')\n",
    "        # Cleaning-up\n",
    "        cdo.cleanTempDir() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea02eb4-abfd-458e-b87c-bc4c76a66ee8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATING MOVING-BASELINE ANOMALIES FOR EACH DATASET OVER THE PACIFIC\n",
    "# =============================================================================\n",
    "\n",
    "# CMIP6 HighResMIP\n",
    "bounds_df = pd.read_csv('./data/Centred_BS_bounds_CMIP6_HIGHRESMIP_1950-2050.csv')\n",
    "for model, exp_type in tqdm(list(product(HIGHRESMIP_MODEL_PATH_SUFFIX, EXP_TYPES))):\n",
    "    # Creating a {model}_{exp_type} directory if it doesn't exist\n",
    "    if os.path.exists(f'./data/anomalies/{model}_{exp_type}/') == False:\n",
    "        os.mkdir(f'./data/anomalies/{model}_{exp_type}/')\n",
    "    ds = xr.open_mfdataset(f'./data/thetao_con/{model}_{exp_type}/BILINTERP_PAC_THETAO_CON_CMIP6_HIGHRESMIP_{model}_{exp_type}_????.nc')\n",
    "    ds['time'] = pd.date_range(start = '1950-01-01', periods = ds.time.shape[0], freq = '1MS')\n",
    "    \n",
    "    for year in tqdm(np.arange(1950, 2050+1), leave = False):\n",
    "        bs_df = bounds_df[(year>=bounds_df['START_Y']) & (year<=bounds_df['END_Y'])]\n",
    "        bs_start, bs_end = str(bs_df['BS_START'].item()), str(bs_df['BS_END'].item())\n",
    "        \n",
    "        baseline = ds.sel(time = slice(bs_start, bs_end)).groupby('time.month').mean()\n",
    "        anomalies = ds.sel(time = str(year)).groupby('time.month') - baseline\n",
    "        anomalies = anomalies.rename({'thetao_con':'anomaly'}).drop_vars('month')\n",
    "        \n",
    "        anomalies.attrs['standard_name'] = 'anomaly_sea_water_conservative_temperature'\n",
    "        anomalies.attrs['long_name'] = f'Anomaly of Sea Water Conservative Temperature with baseline {bs_start}-{bs_end}'\n",
    "        anomalies.attrs['units'] = 'degC'\n",
    "        \n",
    "        anomalies.to_netcdf(f'./data/anomalies/{model}_{exp_type}/BILINTERP_PAC_ANOM_BS{bs_start}-{bs_end}_CMIP6_HIGHRESMIP_{model}_{exp_type}_{year}.nc')\n",
    "\n",
    "# Observations-based Products and NPD_eORCA025 exps. \n",
    "bounds_df = pd.read_csv('./data/Centred_BS_bounds_NPD_eORCA025_OBS_1976-2023.csv')\n",
    "for dataset in ['ORAS5', 'EN4', 'NPD_eORCA025_ERA5', 'NPD_eORCA025_JRA55']:\n",
    "    if os.path.exists(f'./data/anomalies/{dataset}/') == False:\n",
    "            os.mkdir(f'./data/anomalies/{dataset}/')\n",
    "    for ts in tqdm(pd.date_range(start = '1976-01-01', end = '2023-12-31', freq = '1MS')):\n",
    "        bs_df = bounds_df[(ts.year>=bounds_df['START_Y']) & (ts.year<=bounds_df['END_Y'])]\n",
    "        bs_start, bs_end = bs_df['BS_START'].item(), bs_df['BS_END'].item()\n",
    "        \n",
    "        bs_fnames = []\n",
    "        for _ in range(bs_start, bs_end+1):\n",
    "            bs_fnames += [f'./data/thetao_con/{dataset}/BILINTERP_PAC_THETAO_CON_{dataset}_{_}{ts.month:02d}.nc']\n",
    "            \n",
    "        ds = xr.open_dataset(f'./data/thetao_con/{dataset}/BILINTERP_PAC_THETAO_CON_{dataset}_{ts.year}{ts.month:02d}.nc')\n",
    "        baseline = xr.open_mfdataset(bs_fnames).groupby('time.month').mean()\n",
    "        anomalies = ds.groupby('time.month') - baseline\n",
    "        \n",
    "        anomalies = anomalies.rename({'thetao_con':'anomaly'}).drop_vars('month')\n",
    "        \n",
    "        anomalies.attrs['standard_name'] = 'anomaly_sea_water_conservative_temperature'\n",
    "        anomalies.attrs['long_name'] = f'Anomaly of Sea Water Conservative Temperature with baseline {bs_start}-{bs_end}'\n",
    "        anomalies.attrs['units'] = 'degC'\n",
    "        \n",
    "        anomalies.to_netcdf(f'./data/anomalies/{dataset}/BILINTERP_PAC_ANOM_BS{bs_start}-{bs_end}_{dataset}_{ts.year}{ts.month:02d}.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4b41de-a669-4bc4-a5f0-632d526ef1af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATING DEPTH OF 20°C (Z20) FOR EACH MODEL/OBSERVATIONAL DATASET\n",
    "# =============================================================================\n",
    "\n",
    "# CMIP6 HighResMIP\n",
    "for model, exp_type in tqdm(list(product(HIGHRESMIP_MODEL_PATH_SUFFIX, EXP_TYPES))):\n",
    "    ds_z20 = []\n",
    "    for year in tqdm(np.arange(1950, 2050+1), leave = False):\n",
    "        ds = xr.open_dataset(f'./data/thetao_con/{model}_{exp_type}/BILINTERP_PAC_THETAO_CON_CMIP6_HIGHRESMIP_{model}_{exp_type}_{year}.nc')\n",
    "        ds['time'] = pd.date_range(start = f'{year}-01-01', periods = ds.time.shape[0], freq = '1MS')\n",
    "        ds = ds.sel(lat = slice(-5,5), lon = slice(140,280))\n",
    "        ds_z20 += [z20_calculator(ds)]\n",
    "    ds_z20 = xr.merge(ds_z20)\n",
    "    ds_z20 = ds_z20.interp(lon = np.arange(140,280.01, 0.1)).mean(dim = ['lat']).expand_dims(dataset = [model])\n",
    "    ds_z20.to_netcdf(f'./data/z20_depths/Z20_DEPTHS_{model}_{exp_type}_1950-2050.nc')\n",
    "\n",
    "# Observations-based Products and NPD_eORCA025 exps. \n",
    "for dataset in ['ORAS5', 'EN4', 'NPD_eORCA025_ERA5', 'NPD_eORCA025_JRA55']:\n",
    "    ds_z20 = []\n",
    "    for ts in tqdm(pd.date_range(start = '1976-01-01', end = '2023-12-31', freq = '1MS')):\n",
    "        ds = xr.open_dataset(f'./data/thetao_con/{dataset}/BILINTERP_PAC_THETAO_CON_{dataset}_{ts.year}{ts.month:02d}.nc')\n",
    "        ds['time'] = pd.date_range(start = f'{year}-01-01', periods = ds.time.shape[0], freq = '1MS')\n",
    "        ds = ds.sel(lat = slice(-5,5), lon = slice(140,280))\n",
    "        ds_z20 += [z20_calculator(ds)]\n",
    "    ds_z20 = xr.merge(ds_z20)\n",
    "    ds_z20 = ds_z20.interp(lon = np.arange(140,280.01, 0.1)).mean(dim = ['lat']).expand_dims(dataset = [model])\n",
    "    ds_z20.to_netcdf(f'./data/z20_depths/Z20_DEPTHS_{dataset}_1950-2050.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685fda7f-eddf-4576-bf5e-7ff6364325b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCULATING ZONAL WIND ANOMALIES FOR CMIP6 HIGHRESMIP AND ERA5 REANALYSIS\n",
    "# =============================================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46217531-df91-4cdb-b343-5526f221013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db42e37-4c88-4615-b417-317a32b0d6c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
